{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e260eb-5106-4ae6-8e5f-2efe306268c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tomotopy as to\n",
    "import tomotopy.coherence as coherence\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090c753-5b48-4e4f-b06e-2947210f7a21",
   "metadata": {},
   "source": [
    "## Loading data & creating a list of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53f2772-f259-45c0-89df-808b50e1c91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>article_body</th>\n",
       "      <th>all_text</th>\n",
       "      <th>text_lem</th>\n",
       "      <th>date</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>city</th>\n",
       "      <th>md_index</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>«Женщины для утех» по-прежнему нужны: Япония и...</td>\n",
       "      <td>Во время колонизации Кореи Японией в XX веке к...</td>\n",
       "      <td>Во время колонизации Кореи Японией в XX веке к...</td>\n",
       "      <td>«Женщины для утех» по-прежнему нужны: Япония и...</td>\n",
       "      <td>женщина утеха нужный япония китай борьба время...</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>ИА Regnum</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2.312</td>\n",
       "      <td>http://regnum.ru/news/2048238.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>В Норвегии мигрантов научат не насиловать женщин</td>\n",
       "      <td>Наплыв беженцев из Сирии и других стран Ближне...</td>\n",
       "      <td>\\n                                            ...</td>\n",
       "      <td>В Норвегии мигрантов научат не насиловать женщ...</td>\n",
       "      <td>норвегия мигрант научить насиловать беженец си...</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Известия (iz.ru)</td>\n",
       "      <td>Москва</td>\n",
       "      <td>1.113</td>\n",
       "      <td>http://izvestia.ru/news/600956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>В Кельне задержали первого подозреваемого в на...</td>\n",
       "      <td>\\tПрокуратура Кельна сообщила о задержании пер...</td>\n",
       "      <td>Сейчас+6˚CСейчас в Санкт-ПетербургеОблачно, Бе...</td>\n",
       "      <td>В Кельне задержали первого подозреваемого в на...</td>\n",
       "      <td>кёльн задержать первый подозревать нападение п...</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Фонтанка (fontanka.ru)</td>\n",
       "      <td>Санкт-Петербург</td>\n",
       "      <td>1.186</td>\n",
       "      <td>http://www.fontanka.ru/2016/01/05/077/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>В Дании полицейские научат беженцев вежливому ...</td>\n",
       "      <td>В одной из пяти административных областей Дани...</td>\n",
       "      <td>В одной из пяти административных областей Дани...</td>\n",
       "      <td>В Дании полицейские научат беженцев вежливому ...</td>\n",
       "      <td>дания полицейский научить беженец вежливый обр...</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Российская газета (rg.ru)</td>\n",
       "      <td>Москва</td>\n",
       "      <td>1.266</td>\n",
       "      <td>http://www.rg.ru/2016/01/05/keln-site.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>А каждого Михеля демократично переименуют в Му...</td>\n",
       "      <td>Наш спецкор Дарья Асламова выясняет, в чем при...</td>\n",
       "      <td>В теплом кафе мой собеседник небрежно скидывае...</td>\n",
       "      <td>А каждого Михеля демократично переименуют в Му...</td>\n",
       "      <td>михель демократично переименовать спецкор дарь...</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>Комсомольская правда (kp.ru)</td>\n",
       "      <td>Москва</td>\n",
       "      <td>0.960</td>\n",
       "      <td>http://www.kp.ru/daily/26476/3347751/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15337</th>\n",
       "      <td>15338</td>\n",
       "      <td>«Фантазируя об изнасиловании, женщина чувствуе...</td>\n",
       "      <td>Почему во время месячных хочется больше секса,...</td>\n",
       "      <td>\\n— Получаю особенное удовольствие от секса во...</td>\n",
       "      <td>«Фантазируя об изнасиловании, женщина чувствуе...</td>\n",
       "      <td>фантазировать изнасилование женщина чувствоват...</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>Газета.Ru</td>\n",
       "      <td>Москва</td>\n",
       "      <td>1.963</td>\n",
       "      <td>https://www.gazeta.ru/culture/news/2023/12/28/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15338</th>\n",
       "      <td>15339</td>\n",
       "      <td>Обвиняемого в домогательствах екатеринбургског...</td>\n",
       "      <td>Обвиняемого в домогательствах екатеринбургског...</td>\n",
       "      <td>6 октября – ИА SM.News. Обвиняемого в домогате...</td>\n",
       "      <td>Обвиняемого в домогательствах екатеринбургског...</td>\n",
       "      <td>обвинять домогательство екатеринбургский масса...</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>Eadaily.com</td>\n",
       "      <td>Москва</td>\n",
       "      <td>1.469</td>\n",
       "      <td>https://eadaily.com/ru/news/2023/12/29/prosto-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15339</th>\n",
       "      <td>15340</td>\n",
       "      <td>Анджелина Джоли и Гвинет Пэлтроу обвинили Вайн...</td>\n",
       "      <td>Звезды Голливуда Анджелина Джоли и Гвинет Пэлт...</td>\n",
       "      <td>\\n                                            ...</td>\n",
       "      <td>Анджелина Джоли и Гвинет Пэлтроу обвинили Вайн...</td>\n",
       "      <td>анджелина джоля гвинет пэлтроу обвинить вайншт...</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>Известия (iz.ru)</td>\n",
       "      <td>Москва</td>\n",
       "      <td>1.200</td>\n",
       "      <td>https://iz.ru/1628155/2023-12-29/brata-maikla-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15340</th>\n",
       "      <td>15341</td>\n",
       "      <td>Адвокат Людмила Айвар рассказала, как российск...</td>\n",
       "      <td>Адвокат Людмила Айвар рассказала, как российск...</td>\n",
       "      <td>7 марта 2023, 16:59 — Общественная служба но...</td>\n",
       "      <td>Адвокат Людмила Айвар рассказала, как российск...</td>\n",
       "      <td>адвокат людмила айвар рассказать российский же...</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>Общественная служба новостей (osnmedia.ru)</td>\n",
       "      <td>Москва</td>\n",
       "      <td>0.959</td>\n",
       "      <td>https://www.osnmedia.ru/kultura/bolee-600-deya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15341</th>\n",
       "      <td>15342</td>\n",
       "      <td>Пэрис Хилтон рассказала о сексуальном насилии,...</td>\n",
       "      <td>Американская актриса и модель Пэрис Хилтон рас...</td>\n",
       "      <td>Американская актриса и модель Пэрис Хилтон рас...</td>\n",
       "      <td>Пэрис Хилтон рассказала о сексуальном насилии,...</td>\n",
       "      <td>пэрис хилтон рассказать сексуальный насилие пе...</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>Газета.Ru</td>\n",
       "      <td>Москва</td>\n",
       "      <td>1.324</td>\n",
       "      <td>https://www.gazeta.ru/culture/news/2023/12/30/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15342 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           headline  \\\n",
       "0          1  «Женщины для утех» по-прежнему нужны: Япония и...   \n",
       "1          2   В Норвегии мигрантов научат не насиловать женщин   \n",
       "2          3  В Кельне задержали первого подозреваемого в на...   \n",
       "3          4  В Дании полицейские научат беженцев вежливому ...   \n",
       "4          5  А каждого Михеля демократично переименуют в Му...   \n",
       "...      ...                                                ...   \n",
       "15337  15338  «Фантазируя об изнасиловании, женщина чувствуе...   \n",
       "15338  15339  Обвиняемого в домогательствах екатеринбургског...   \n",
       "15339  15340  Анджелина Джоли и Гвинет Пэлтроу обвинили Вайн...   \n",
       "15340  15341  Адвокат Людмила Айвар рассказала, как российск...   \n",
       "15341  15342  Пэрис Хилтон рассказала о сексуальном насилии,...   \n",
       "\n",
       "                                             description  \\\n",
       "0      Во время колонизации Кореи Японией в XX веке к...   \n",
       "1      Наплыв беженцев из Сирии и других стран Ближне...   \n",
       "2      \\tПрокуратура Кельна сообщила о задержании пер...   \n",
       "3      В одной из пяти административных областей Дани...   \n",
       "4      Наш спецкор Дарья Асламова выясняет, в чем при...   \n",
       "...                                                  ...   \n",
       "15337  Почему во время месячных хочется больше секса,...   \n",
       "15338  Обвиняемого в домогательствах екатеринбургског...   \n",
       "15339  Звезды Голливуда Анджелина Джоли и Гвинет Пэлт...   \n",
       "15340  Адвокат Людмила Айвар рассказала, как российск...   \n",
       "15341  Американская актриса и модель Пэрис Хилтон рас...   \n",
       "\n",
       "                                            article_body  \\\n",
       "0      Во время колонизации Кореи Японией в XX веке к...   \n",
       "1      \\n                                            ...   \n",
       "2      Сейчас+6˚CСейчас в Санкт-ПетербургеОблачно, Бе...   \n",
       "3      В одной из пяти административных областей Дани...   \n",
       "4      В теплом кафе мой собеседник небрежно скидывае...   \n",
       "...                                                  ...   \n",
       "15337  \\n— Получаю особенное удовольствие от секса во...   \n",
       "15338  6 октября – ИА SM.News. Обвиняемого в домогате...   \n",
       "15339  \\n                                            ...   \n",
       "15340    7 марта 2023, 16:59 — Общественная служба но...   \n",
       "15341  Американская актриса и модель Пэрис Хилтон рас...   \n",
       "\n",
       "                                                all_text  \\\n",
       "0      «Женщины для утех» по-прежнему нужны: Япония и...   \n",
       "1      В Норвегии мигрантов научат не насиловать женщ...   \n",
       "2      В Кельне задержали первого подозреваемого в на...   \n",
       "3      В Дании полицейские научат беженцев вежливому ...   \n",
       "4      А каждого Михеля демократично переименуют в Му...   \n",
       "...                                                  ...   \n",
       "15337  «Фантазируя об изнасиловании, женщина чувствуе...   \n",
       "15338  Обвиняемого в домогательствах екатеринбургског...   \n",
       "15339  Анджелина Джоли и Гвинет Пэлтроу обвинили Вайн...   \n",
       "15340  Адвокат Людмила Айвар рассказала, как российск...   \n",
       "15341  Пэрис Хилтон рассказала о сексуальном насилии,...   \n",
       "\n",
       "                                                text_lem       date  \\\n",
       "0      женщина утеха нужный япония китай борьба время... 2016-01-03   \n",
       "1      норвегия мигрант научить насиловать беженец си... 2016-01-04   \n",
       "2      кёльн задержать первый подозревать нападение п... 2016-01-05   \n",
       "3      дания полицейский научить беженец вежливый обр... 2016-01-05   \n",
       "4      михель демократично переименовать спецкор дарь... 2016-01-06   \n",
       "...                                                  ...        ...   \n",
       "15337  фантазировать изнасилование женщина чувствоват... 2023-12-28   \n",
       "15338  обвинять домогательство екатеринбургский масса... 2023-12-29   \n",
       "15339  анджелина джоля гвинет пэлтроу обвинить вайншт... 2023-12-29   \n",
       "15340  адвокат людмила айвар рассказать российский же... 2023-12-30   \n",
       "15341  пэрис хилтон рассказать сексуальный насилие пе... 2023-12-30   \n",
       "\n",
       "                                        newspaper             city  md_index  \\\n",
       "0                                       ИА Regnum           Москва     2.312   \n",
       "1                                Известия (iz.ru)           Москва     1.113   \n",
       "2                          Фонтанка (fontanka.ru)  Санкт-Петербург     1.186   \n",
       "3                       Российская газета (rg.ru)           Москва     1.266   \n",
       "4                    Комсомольская правда (kp.ru)           Москва     0.960   \n",
       "...                                           ...              ...       ...   \n",
       "15337                                   Газета.Ru           Москва     1.963   \n",
       "15338                                 Eadaily.com           Москва     1.469   \n",
       "15339                            Известия (iz.ru)           Москва     1.200   \n",
       "15340  Общественная служба новостей (osnmedia.ru)           Москва     0.959   \n",
       "15341                                   Газета.Ru           Москва     1.324   \n",
       "\n",
       "                                                     url  \n",
       "0                     http://regnum.ru/news/2048238.html  \n",
       "1                         http://izvestia.ru/news/600956  \n",
       "2                 http://www.fontanka.ru/2016/01/05/077/  \n",
       "3             http://www.rg.ru/2016/01/05/keln-site.html  \n",
       "4                  http://www.kp.ru/daily/26476/3347751/  \n",
       "...                                                  ...  \n",
       "15337  https://www.gazeta.ru/culture/news/2023/12/28/...  \n",
       "15338  https://eadaily.com/ru/news/2023/12/29/prosto-...  \n",
       "15339  https://iz.ru/1628155/2023-12-29/brata-maikla-...  \n",
       "15340  https://www.osnmedia.ru/kultura/bolee-600-deya...  \n",
       "15341  https://www.gazeta.ru/culture/news/2023/12/30/...  \n",
       "\n",
       "[15342 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data - dataset containing lemmatized texts\n",
    "names = ['id',\n",
    "         'headline',\n",
    "         'description',\n",
    "         'article_body',\n",
    "         'all_text',\n",
    "         'text_lem',\n",
    "         'date',\n",
    "         'newspaper',\n",
    "         'city',\n",
    "         'md_index',\n",
    "         'url']\n",
    "\n",
    "data = pd.read_excel('SV-women-data-lem.xlsx',\n",
    "                     index_col = 0,\n",
    "                     names = names)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed58762-c2cb-4205-8236-e75da279b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting docs from data\n",
    "docs = pd.DataFrame(data.text_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ed479f-f461-4c1c-b39e-f90de991e5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words is 63240\n"
     ]
    }
   ],
   "source": [
    "# Extract unique words and calculate their number\n",
    "uniq_words = list(filter(lambda x: x, set(docs.text_lem.str.cat(sep=' ').strip().split(' '))))\n",
    "uniq_words_len = len(uniq_words)\n",
    "print('The number of unique words is', uniq_words_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04ae991-45d6-4b0c-b1b2-272c470109b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform documents into word lists\n",
    "words_in_docs = list(map(lambda x: x.split(), docs.text_lem.dropna().values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddbe35e-8d49-4fc3-ac0f-1445e9fa6ee6",
   "metadata": {},
   "source": [
    "## Main attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "844bee65-0793-4f8e-a361-8a865b0a5b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Topic distribution for each document (probabilities)\n",
    "mdl.docs[0].get_topic_dist() \n",
    "\n",
    "# Word distribution for each topic (only probabilities)\n",
    "mdl.get_topic_word_dist(topic_id = 0)\n",
    "\n",
    "# Word distribution for each topic (words + probabilities)\n",
    "mdl.get_topic_words(topic_id=0, top_n=50)\n",
    "\n",
    "# Number of words allocated to each topic (num)\n",
    "mdl.get_count_by_topics()\n",
    "\n",
    "# hLDA Words distribution for each of the live topics (only probabilities)\n",
    "words_topics_distr = list(map(lambda x: hlda.get_topic_word_dist(x) if hlda.is_live_topic(x) else [], range(hlda.k)))\n",
    "'''\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc1d51-3902-44f0-ba3c-0d507f0a4b27",
   "metadata": {},
   "source": [
    "## Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3e1f8f-ed80-4555-b1b9-1eb046eb4dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HYPERPARAMETERS FOR FITTING THE MODELS \n",
      "--------------------------------------- \n",
      "Models: ['LDAModel', 'HLDAModel', 'PAModel', 'HPAModel', 'CTModel'] \n",
      "--------------------------------------- \n",
      "Num of topics: [5, 10, 15, 20, 25, 30, 40, 50, 60, 70] \n",
      "Alpha: 0.001 \n",
      "Eta: [1e-05, 0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.5, 0.7, 1] \n",
      "Gamma: 0.001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random seed to get reproducable results\n",
    "seed = 12345\n",
    "\n",
    "#set the number of topics to fit models\n",
    "num_topics = list(np.arange(5, 30, 5)) + list(np.arange(30, 80, 10))\n",
    "\n",
    "#set the value of parameters alpha and eta\n",
    "myalpha = 0.001 \n",
    "myeta = [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.2,  0.3, 0.5, 0.7, 1]\n",
    "# eta for all the models except HLDA\n",
    "myeta_short = [0.00001, 0.001, 0.1, 0.5, 1]\n",
    "\n",
    "# depth of the hierarchical models\n",
    "level = 3\n",
    "\n",
    "#set value of parameter gamma\n",
    "gamma = 0.001\n",
    "\n",
    "#set the name of the file for recording the results\n",
    "myfile = 'TM-models-fit.csv'\n",
    "\n",
    "# List of models and params for model fitting\n",
    "model_names = ['LDAModel', 'HLDAModel', 'PAModel', 'HPAModel', 'CTModel']\n",
    "workers = 1\n",
    "iter = 100\n",
    "\n",
    "#print all the params\n",
    "params = [num_topics, myalpha, myeta, gamma]\n",
    "print('\\nHYPERPARAMETERS FOR FITTING THE MODELS \\n--------------------------------------- \\n', \\\n",
    "      'Models: {} \\n--------------------------------------- \\n'.format(model_names), \\\n",
    "      'Num of topics: {} \\nAlpha: {} \\nEta: {} \\nGamma: {} \\n'.format(*params), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2e4767-6bf3-4f41-b5cd-791619a634ff",
   "metadata": {},
   "source": [
    "## Fitting the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43789e00-5413-48f2-be42-556ebbce6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models and params for model fitting\n",
    "model_names = ['LDAModel', 'HLDAModel', 'PAModel', 'HPAModel', 'CTModel']\n",
    "workers = 1\n",
    "iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bdd6e61-df43-47e2-9618-0c3803026577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LDAModel \n",
      "Num of topics: 5 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.5778704536662338 \n",
      "Log-likelihood: -8.635658966522472\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 10 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.6150202463664542 \n",
      "Log-likelihood: -8.757591297037758\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 15 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.8202113336355197 \n",
      "Log-likelihood: -8.811911416973665\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 20 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.0356906049040804 \n",
      "Log-likelihood: -8.797220451121815\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 25 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.1065588985823833 \n",
      "Log-likelihood: -8.821437682624607\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 30 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.249233671242091 \n",
      "Log-likelihood: -8.840772661521282\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 40 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.1779757385093896 \n",
      "Log-likelihood: -8.852659167277995\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 50 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.4852130486588138 \n",
      "Log-likelihood: -8.883684908170544\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 60 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.481226781262313 \n",
      "Log-likelihood: -8.886854973213087\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 70 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.573124674579185 \n",
      "Log-likelihood: -8.894666750021873\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.5523904881325827 \n",
      "Log-likelihood: -8.472779074368527\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.5870279302961026 \n",
      "Log-likelihood: -8.544953316705541\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.7994505358763024 \n",
      "Log-likelihood: -8.573776691891478\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.0079168853863534 \n",
      "Log-likelihood: -8.569689985326049\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.9932517938279621 \n",
      "Log-likelihood: -8.570793370328591\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.059288428705218 \n",
      "Log-likelihood: -8.575843110712125\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.105927015193695 \n",
      "Log-likelihood: -8.567319747423365\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.4168429306596417 \n",
      "Log-likelihood: -8.580246738404442\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.6366868653010775 \n",
      "Log-likelihood: -8.571006882090405\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.560320742137253 \n",
      "Log-likelihood: -8.579423190354085\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.5980085138098141 \n",
      "Log-likelihood: -8.2822601139218\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.558604246140629 \n",
      "Log-likelihood: -8.348436362858475\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.9498255277364958 \n",
      "Log-likelihood: -8.364008529695955\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.0111475013555653 \n",
      "Log-likelihood: -8.388617663070569\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.0627645459105803 \n",
      "Log-likelihood: -8.368329945181145\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.275371637227306 \n",
      "Log-likelihood: -8.382837687644582\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.2693267806747643 \n",
      "Log-likelihood: -8.421628471238396\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.8746160549158053 \n",
      "Log-likelihood: -8.405012608432108\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.1 \n",
      "Coherence: -3.344010215679805 \n",
      "Log-likelihood: -8.447200840021381\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.1 \n",
      "Coherence: -4.806882430560782 \n",
      "Log-likelihood: -8.420369728178326\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.6293086583982188 \n",
      "Log-likelihood: -8.351664762955897\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.5929880197671635 \n",
      "Log-likelihood: -8.477491863658363\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.5 \n",
      "Coherence: -2.722286827878061 \n",
      "Log-likelihood: -8.491011162953157\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.5 \n",
      "Coherence: -4.266550997649235 \n",
      "Log-likelihood: -8.505240449949731\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.5 \n",
      "Coherence: -6.244982635239394 \n",
      "Log-likelihood: -8.478182311130443\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.5 \n",
      "Coherence: -6.956871311185805 \n",
      "Log-likelihood: -8.474591562440265\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.5 \n",
      "Coherence: -7.4861658446932555 \n",
      "Log-likelihood: -8.51034186036514\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.5 \n",
      "Coherence: -8.304049620831618 \n",
      "Log-likelihood: -8.501205892852658\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.5 \n",
      "Coherence: -6.098122334153765 \n",
      "Log-likelihood: -8.566145573582116\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.5 \n",
      "Coherence: -6.797351412531287 \n",
      "Log-likelihood: -8.525585818912928\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 5 \n",
      "Eta: 1 \n",
      "Coherence: -1.5568070781628878 \n",
      "Log-likelihood: -8.433136008390639\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 10 \n",
      "Eta: 1 \n",
      "Coherence: -1.490926863053502 \n",
      "Log-likelihood: -8.573678756177065\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 15 \n",
      "Eta: 1 \n",
      "Coherence: -5.097671259515105 \n",
      "Log-likelihood: -8.601549856575796\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 20 \n",
      "Eta: 1 \n",
      "Coherence: -5.802284691655415 \n",
      "Log-likelihood: -8.577950968236415\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 25 \n",
      "Eta: 1 \n",
      "Coherence: -7.111044227292286 \n",
      "Log-likelihood: -8.472078970405635\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 30 \n",
      "Eta: 1 \n",
      "Coherence: -5.586591287790214 \n",
      "Log-likelihood: -8.540049014176532\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 40 \n",
      "Eta: 1 \n",
      "Coherence: -3.9691006117419603 \n",
      "Log-likelihood: -8.531266573900137\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 50 \n",
      "Eta: 1 \n",
      "Coherence: -4.721471261986072 \n",
      "Log-likelihood: -8.446052296638573\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 60 \n",
      "Eta: 1 \n",
      "Coherence: -3.763458273210867 \n",
      "Log-likelihood: -8.515007734238637\n",
      "------------------------------\n",
      "Model: LDAModel \n",
      "Num of topics: 70 \n",
      "Eta: 1 \n",
      "Coherence: -3.8833458617437495 \n",
      "Log-likelihood: -8.510968676342912\n",
      "------------------------------\n",
      "Model: HLDAModel \n",
      "Num of topics: 881 \n",
      "Eta: 1e-05 \n",
      "Coherence: -4.95346193279525 \n",
      "Log-likelihood: -8.561474159845956\n",
      "------------------------------\n",
      "Model: HLDAModel \n",
      "Num of topics: 1375 \n",
      "Eta: 0.0001 \n",
      "Coherence: -5.455201629823559 \n",
      "Log-likelihood: -8.413965696298279\n",
      "------------------------------\n",
      "Model: HLDAModel \n",
      "Num of topics: 960 \n",
      "Eta: 0.001 \n",
      "Coherence: -8.328110055467949 \n",
      "Log-likelihood: -8.247043004052317\n",
      "------------------------------\n",
      "Model: HLDAModel \n",
      "Num of topics: 336 \n",
      "Eta: 0.01 \n",
      "Coherence: -8.37014604743548 \n",
      "Log-likelihood: -8.137927008105041\n",
      "------------------------------\n",
      "Model: HLDAModel \n",
      "Num of topics: 29 \n",
      "Eta: 0.1 \n",
      "Coherence: -8.596187348217391 \n",
      "Log-likelihood: -8.315819189911494\n",
      "------------------------------\n",
      "Model: HLDAModel \n",
      "Num of topics: 12 \n",
      "Eta: 0.2 \n",
      "Coherence: -4.5705310998944 \n",
      "Log-likelihood: -8.32406233997504\n",
      "------------------------------\n",
      "Model: HLDAModel \n",
      "Num of topics: 9 \n",
      "Eta: 0.3 \n",
      "Coherence: -3.7066480454047337 \n",
      "Log-likelihood: -8.334500160660339\n",
      "------------------------------\n",
      "Model: HLDAModel \n",
      "Num of topics: 4 \n",
      "Eta: 0.5 \n",
      "Coherence: -2.0510542102763782 \n",
      "Log-likelihood: -8.358642082221667\n",
      "------------------------------\n",
      "Model: HLDAModel \n",
      "Num of topics: 4 \n",
      "Eta: 0.7 \n",
      "Coherence: -1.877557132572644 \n",
      "Log-likelihood: -8.382657785562117\n",
      "------------------------------\n",
      "Model: HLDAModel \n",
      "Num of topics: 4 \n",
      "Eta: 1 \n",
      "Coherence: -1.3551410899687797 \n",
      "Log-likelihood: -8.416453023365115\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 5 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.693924548904438 \n",
      "Log-likelihood: -9.43618050362715\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 10 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.6347082202769236 \n",
      "Log-likelihood: -9.638879753562716\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 15 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.3326771745415817 \n",
      "Log-likelihood: -9.856381752168042\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 20 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.0508409196502018 \n",
      "Log-likelihood: -9.972859616301053\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 25 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.3216488161119693 \n",
      "Log-likelihood: -10.059850595342018\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 30 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.05041857051901 \n",
      "Log-likelihood: -10.10020798154384\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 40 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.8709245852078484 \n",
      "Log-likelihood: -10.203650821787003\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 50 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.7292138563321835 \n",
      "Log-likelihood: -10.270324869285593\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 60 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.4378883802993077 \n",
      "Log-likelihood: -10.349612015412774\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 70 \n",
      "Eta: 1e-05 \n",
      "Coherence: -3.606005751263108 \n",
      "Log-likelihood: -10.399271578242335\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.6166646487113088 \n",
      "Log-likelihood: -9.384430013398955\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.5661175280579223 \n",
      "Log-likelihood: -9.63078151460463\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.4778668069053023 \n",
      "Log-likelihood: -9.847484753227613\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.9585855194278807 \n",
      "Log-likelihood: -10.017500774254884\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.7059222381691146 \n",
      "Log-likelihood: -10.076428814426095\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.0074187331748057 \n",
      "Log-likelihood: -10.158128715941883\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.8986958165704872 \n",
      "Log-likelihood: -10.28370112746474\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.659819610460391 \n",
      "Log-likelihood: -10.38921097396021\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.458298649118877 \n",
      "Log-likelihood: -10.42045204853434\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.001 \n",
      "Coherence: -3.747778310133531 \n",
      "Log-likelihood: -10.526100645710168\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.6771907954150256 \n",
      "Log-likelihood: -9.613188421233517\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.662356202934505 \n",
      "Log-likelihood: -9.962177660914612\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.4899936389468746 \n",
      "Log-likelihood: -10.245933864298534\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.7607672541257091 \n",
      "Log-likelihood: -10.422175852788355\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.1477246674774664 \n",
      "Log-likelihood: -10.668185347655216\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.2457179301339154 \n",
      "Log-likelihood: -10.646885743101738\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.1 \n",
      "Coherence: -5.62473228738892 \n",
      "Log-likelihood: -10.92079191714506\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.1 \n",
      "Coherence: -3.2267127485393843 \n",
      "Log-likelihood: -10.878281635302542\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.782533649185984 \n",
      "Log-likelihood: -10.995413725907193\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.1 \n",
      "Coherence: -10.526352692466373 \n",
      "Log-likelihood: -10.952424697370889\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.6790862291890896 \n",
      "Log-likelihood: -9.727786418109835\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.5 \n",
      "Coherence: -2.898434257701337 \n",
      "Log-likelihood: -9.87132383697566\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.2534100402663058 \n",
      "Log-likelihood: -10.287369551568238\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.5 \n",
      "Coherence: -7.139555196213538 \n",
      "Log-likelihood: -10.298060158207477\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.5 \n",
      "Coherence: -12.908524619286176 \n",
      "Log-likelihood: -10.25072623560403\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.5 \n",
      "Coherence: -7.202634977359708 \n",
      "Log-likelihood: -10.397910518222195\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.5 \n",
      "Coherence: -5.566617928300384 \n",
      "Log-likelihood: -10.222947704370734\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.5 \n",
      "Coherence: -12.105459872219773 \n",
      "Log-likelihood: -10.39035762128202\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.5 \n",
      "Coherence: -12.001725042006315 \n",
      "Log-likelihood: -10.311507450640216\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.5 \n",
      "Coherence: -5.257086650653572 \n",
      "Log-likelihood: -10.363284636968618\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 5 \n",
      "Eta: 1 \n",
      "Coherence: -1.4519754249647523 \n",
      "Log-likelihood: -9.662305618139765\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 10 \n",
      "Eta: 1 \n",
      "Coherence: -1.2718038364140059 \n",
      "Log-likelihood: -9.83193860466609\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 15 \n",
      "Eta: 1 \n",
      "Coherence: -5.284513522300912 \n",
      "Log-likelihood: -9.843165804113445\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 20 \n",
      "Eta: 1 \n",
      "Coherence: -4.630990703897102 \n",
      "Log-likelihood: -9.902308693910632\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 25 \n",
      "Eta: 1 \n",
      "Coherence: -15.295230896619842 \n",
      "Log-likelihood: -9.909392015994927\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 30 \n",
      "Eta: 1 \n",
      "Coherence: -5.680941877103543 \n",
      "Log-likelihood: -9.933470051924456\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 40 \n",
      "Eta: 1 \n",
      "Coherence: -2.548368476620662 \n",
      "Log-likelihood: -9.947887727217893\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 50 \n",
      "Eta: 1 \n",
      "Coherence: -14.042387308915403 \n",
      "Log-likelihood: -9.92678481138964\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 60 \n",
      "Eta: 1 \n",
      "Coherence: -6.7450133756963915 \n",
      "Log-likelihood: -9.728215737649055\n",
      "------------------------------\n",
      "Model: PAModel \n",
      "Num of topics: 70 \n",
      "Eta: 1 \n",
      "Coherence: -8.28718380431198 \n",
      "Log-likelihood: -9.92103714907374\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 5 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.7166106176095033 \n",
      "Log-likelihood: -9.48715533413469\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 10 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.5219461066079043 \n",
      "Log-likelihood: -9.737822036812457\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 15 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.494696404089651 \n",
      "Log-likelihood: -9.534613833575532\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 20 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.6416898678545426 \n",
      "Log-likelihood: -9.700785679072204\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 25 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.4628875033142756 \n",
      "Log-likelihood: -9.771868967415864\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 30 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.6116807532734647 \n",
      "Log-likelihood: -9.887664952794681\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 40 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.5920919168807321 \n",
      "Log-likelihood: -9.887510956223942\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 50 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.7647903945005492 \n",
      "Log-likelihood: -10.024461190737584\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 60 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.6841283096321342 \n",
      "Log-likelihood: -10.118593997705242\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 70 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.6348767672841433 \n",
      "Log-likelihood: -10.077552235306838\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.659650335752553 \n",
      "Log-likelihood: -9.367138529403842\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.3256700014820744 \n",
      "Log-likelihood: -9.499260256244044\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.4540674734728352 \n",
      "Log-likelihood: -9.472839794542137\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.5521654660995414 \n",
      "Log-likelihood: -9.498943238818065\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.353156543145807 \n",
      "Log-likelihood: -9.58986869208762\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.4776491672756806 \n",
      "Log-likelihood: -9.650574740016207\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.5126929218799 \n",
      "Log-likelihood: -9.801733961794541\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.5029031026090631 \n",
      "Log-likelihood: -9.89172213072634\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.542748415923656 \n",
      "Log-likelihood: -9.89732284336646\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.5215975512966464 \n",
      "Log-likelihood: -9.88632601223671\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.3499211530822077 \n",
      "Log-likelihood: -9.372328034936775\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.3406191752436871 \n",
      "Log-likelihood: -9.484931235550535\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.312841538779882 \n",
      "Log-likelihood: -9.778869460577456\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.3212570763814524 \n",
      "Log-likelihood: -9.576166683254833\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.3072488732739878 \n",
      "Log-likelihood: -9.504060927078278\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.317378126199185 \n",
      "Log-likelihood: -9.457305785562001\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.3359393643498414 \n",
      "Log-likelihood: -9.513761825854697\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.3053333188568883 \n",
      "Log-likelihood: -9.440748825795408\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.3161443686914842 \n",
      "Log-likelihood: -9.448982243394065\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.475863047313614 \n",
      "Log-likelihood: -9.427024042908416\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.4564265448259954 \n",
      "Log-likelihood: -8.831634106379108\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.4401268897730413 \n",
      "Log-likelihood: -8.552212398729345\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.461333181924677 \n",
      "Log-likelihood: -8.50855539538572\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.5216785283586853 \n",
      "Log-likelihood: -8.502269997216088\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.490074614377254 \n",
      "Log-likelihood: -8.500120916395117\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.48828525338341 \n",
      "Log-likelihood: -8.502279853990919\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.4479190317538222 \n",
      "Log-likelihood: -8.504751383811394\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.4969372158092256 \n",
      "Log-likelihood: -8.484627258334207\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.5359670566605512 \n",
      "Log-likelihood: -8.488390213120818\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.4884737931594385 \n",
      "Log-likelihood: -8.485068564802413\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 5 \n",
      "Eta: 1 \n",
      "Coherence: -1.4575600550383427 \n",
      "Log-likelihood: -8.475046272476133\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 10 \n",
      "Eta: 1 \n",
      "Coherence: -1.6772502565997864 \n",
      "Log-likelihood: -8.467601983112688\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 15 \n",
      "Eta: 1 \n",
      "Coherence: -1.5957461029113909 \n",
      "Log-likelihood: -8.459955650291805\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 20 \n",
      "Eta: 1 \n",
      "Coherence: -1.5129572788017172 \n",
      "Log-likelihood: -8.440166915342482\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 25 \n",
      "Eta: 1 \n",
      "Coherence: -1.5017607863822136 \n",
      "Log-likelihood: -8.441786851432079\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 30 \n",
      "Eta: 1 \n",
      "Coherence: -1.5075885523882306 \n",
      "Log-likelihood: -8.437982304782786\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 40 \n",
      "Eta: 1 \n",
      "Coherence: -1.4101530689873847 \n",
      "Log-likelihood: -8.45219408136051\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 50 \n",
      "Eta: 1 \n",
      "Coherence: -1.4885690643860174 \n",
      "Log-likelihood: -8.440185046158453\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 60 \n",
      "Eta: 1 \n",
      "Coherence: -1.4849931922656066 \n",
      "Log-likelihood: -8.446290175826835\n",
      "------------------------------\n",
      "Model: HPAModel \n",
      "Num of topics: 70 \n",
      "Eta: 1 \n",
      "Coherence: -1.504292859228725 \n",
      "Log-likelihood: -8.435324312146854\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 5 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.4990200278019832 \n",
      "Log-likelihood: -7.751767918944299\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 10 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.806794252231184 \n",
      "Log-likelihood: -7.025322910526604\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 15 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.0122373236563513 \n",
      "Log-likelihood: -6.894014097727763\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 20 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.980441401305385 \n",
      "Log-likelihood: -6.934330040592351\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 25 \n",
      "Eta: 1e-05 \n",
      "Coherence: -1.9829415912108233 \n",
      "Log-likelihood: -6.953753125050885\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 30 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.109993554523069 \n",
      "Log-likelihood: -6.938384426407668\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 40 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.0860893452838605 \n",
      "Log-likelihood: -7.00473608631542\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 50 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.159752223911771 \n",
      "Log-likelihood: -7.070072091787518\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 60 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.490605405946877 \n",
      "Log-likelihood: -6.84580868339799\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 70 \n",
      "Eta: 1e-05 \n",
      "Coherence: -2.2991278383421943 \n",
      "Log-likelihood: -7.252303129972673\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.5460362361925717 \n",
      "Log-likelihood: -7.623363110301734\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.8397297812829705 \n",
      "Log-likelihood: -6.955520891459149\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.001 \n",
      "Coherence: -1.8943655917963227 \n",
      "Log-likelihood: -6.829794824151643\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.004919845335418 \n",
      "Log-likelihood: -6.783703371819858\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.139214724760562 \n",
      "Log-likelihood: -6.644929805722942\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.017718726885968 \n",
      "Log-likelihood: -6.878577778066669\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.3406878722230333 \n",
      "Log-likelihood: -6.629884587044229\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.2553150625393807 \n",
      "Log-likelihood: -6.94871047653291\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.328317597882233 \n",
      "Log-likelihood: -7.018473959235517\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.001 \n",
      "Coherence: -2.3122555603346813 \n",
      "Log-likelihood: -7.14781385720421\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.5506068067714363 \n",
      "Log-likelihood: -7.735565032513108\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.8800235853936855 \n",
      "Log-likelihood: -7.160119940629908\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.0538638212483025 \n",
      "Log-likelihood: -7.096873395261096\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.1 \n",
      "Coherence: -1.939229117000029 \n",
      "Log-likelihood: -7.116046479372132\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.137612399516291 \n",
      "Log-likelihood: -7.169483855625088\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.2927439582704943 \n",
      "Log-likelihood: -6.962219595940526\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.289108604916568 \n",
      "Log-likelihood: -7.327765861182165\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.4950639864588076 \n",
      "Log-likelihood: -7.370709393133022\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.1 \n",
      "Coherence: -2.5315186103822622 \n",
      "Log-likelihood: -7.558671386038707\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.1 \n",
      "Coherence: -3.0911716553796285 \n",
      "Log-likelihood: -7.381164215077652\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 5 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.4562519565059382 \n",
      "Log-likelihood: -8.04699631497335\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 10 \n",
      "Eta: 0.5 \n",
      "Coherence: -1.789288980418672 \n",
      "Log-likelihood: -7.566968124770986\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 15 \n",
      "Eta: 0.5 \n",
      "Coherence: -2.0629168501428174 \n",
      "Log-likelihood: -7.525740063531037\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 20 \n",
      "Eta: 0.5 \n",
      "Coherence: -2.0104216226860574 \n",
      "Log-likelihood: -7.613229246283313\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 25 \n",
      "Eta: 0.5 \n",
      "Coherence: -2.132439670357707 \n",
      "Log-likelihood: -7.736151441339753\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 30 \n",
      "Eta: 0.5 \n",
      "Coherence: -2.317697953663151 \n",
      "Log-likelihood: -7.804722072449981\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 40 \n",
      "Eta: 0.5 \n",
      "Coherence: -3.0059352050475696 \n",
      "Log-likelihood: -7.856750803993967\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 50 \n",
      "Eta: 0.5 \n",
      "Coherence: -3.9311870318474065 \n",
      "Log-likelihood: -8.100579191096132\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 60 \n",
      "Eta: 0.5 \n",
      "Coherence: -6.388555476043066 \n",
      "Log-likelihood: -7.907294962772885\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 70 \n",
      "Eta: 0.5 \n",
      "Coherence: -7.9167742864937365 \n",
      "Log-likelihood: -8.00228658684089\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 5 \n",
      "Eta: 1 \n",
      "Coherence: -1.5096120990748223 \n",
      "Log-likelihood: -8.22849453356763\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 10 \n",
      "Eta: 1 \n",
      "Coherence: -1.8099282255655553 \n",
      "Log-likelihood: -7.8793611794859055\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 15 \n",
      "Eta: 1 \n",
      "Coherence: -2.091198721614256 \n",
      "Log-likelihood: -7.885118148307272\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 20 \n",
      "Eta: 1 \n",
      "Coherence: -2.034149471676556 \n",
      "Log-likelihood: -7.97434473674668\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 25 \n",
      "Eta: 1 \n",
      "Coherence: -2.312396009384724 \n",
      "Log-likelihood: -8.06037764912183\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 30 \n",
      "Eta: 1 \n",
      "Coherence: -2.8350772569375007 \n",
      "Log-likelihood: -8.131751554082872\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 40 \n",
      "Eta: 1 \n",
      "Coherence: -4.863277032337969 \n",
      "Log-likelihood: -8.345074230060982\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 50 \n",
      "Eta: 1 \n",
      "Coherence: -7.125356505003726 \n",
      "Log-likelihood: -8.430884835352295\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 60 \n",
      "Eta: 1 \n",
      "Coherence: -7.684632845704978 \n",
      "Log-likelihood: -8.492313836804023\n",
      "------------------------------\n",
      "Model: CTModel \n",
      "Num of topics: 70 \n",
      "Eta: 1 \n",
      "Coherence: -8.36196736330942 \n",
      "Log-likelihood: -8.54927607343145\n",
      "------------------------------\n",
      "\n",
      "Time of execution (sec) 103935.33294582367\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Delete the file if it extsts (from prev fittings) and start writing into it\n",
    "open(myfile, 'w').close()\n",
    "with open(myfile, 'a') as file: \n",
    "    file.write('Model' + ';' + \n",
    "               'Depth (levels)' + ';' +\n",
    "               'Num of topics' + ';' + \n",
    "               'Alpha' +';' + \n",
    "               'Subalpha' + ';' +\n",
    "               'Eta' +';' + \n",
    "               'Gamma' + ';' +\n",
    "               'Coherence' + ';' + \n",
    "               'Log-likelihood'  + '\\n')\n",
    "\n",
    "# Loop through all model types    \n",
    "for model_name in model_names:\n",
    "\n",
    "    # Loop through eta values\n",
    "    for eta in myeta:\n",
    "    \n",
    "    #If iterating only by eta (HLDA model) or also by number of topics (other models)\n",
    "        if model_name != 'HLDAModel':\n",
    "\n",
    "        # Loop through number of topics (all models except HLDA)\n",
    "            for k in num_topics:\n",
    "\n",
    "                # Iterate only through the short list of eta values\n",
    "                if eta in myeta_short:\n",
    "            \n",
    "                    # Setting parameters dicts for the specific models\n",
    "                    if model_name == 'LDAModel':\n",
    "                        level_run = subalpha_run = gamma_run = None\n",
    "                        params = {'k':k, 'alpha':myalpha, 'eta':eta, 'seed':seed}\n",
    "                    elif 'PAModel' in model_name:\n",
    "                        level_run = level\n",
    "                        subalpha_run = myalpha\n",
    "                        gamma_run = None\n",
    "                        params = {'k1':level_run, 'k2':k, 'alpha':myalpha, 'subalpha':subalpha_run, 'eta':eta, 'seed':seed}\n",
    "                    elif model_name == 'CTModel':\n",
    "                        level_run = subalpha_run = gamma_run = None\n",
    "                        params = {'k':k, 'smoothing_alpha':myalpha, 'eta':eta, 'seed':seed}\n",
    "                        \n",
    "                    else: raise ValueError('Cannot identify model!!! Add some code for this one lol')\n",
    "            \n",
    "                    # Initialization of the models with parameters\n",
    "                    model = eval('to.' + model_name)(**params)\n",
    "                    # Download documents\n",
    "                    list(map(model.add_doc, words_in_docs))\n",
    "                    \n",
    "                    # Train the model\n",
    "                    model.train(workers=workers, iter=iter)\n",
    "                    # Get evaluation metrics\n",
    "                    ch_score = coherence.Coherence(model, top_n = 50).get_score()\n",
    "                    ll_score = model.ll_per_word\n",
    "            \n",
    "                    #Print iteration\n",
    "                    print('Model: {} \\nNum of topics: {} \\nEta: {} \\nCoherence: {} \\nLog-likelihood: {}'.format(model_name, k, eta, ch_score, ll_score))\n",
    "                    #Recording the results to a csv file\n",
    "                    with open(myfile, 'a') as file: \n",
    "                        file.write(model_name + ';' + str(level_run) + ';' + str(k) + ';' + str(myalpha) +';' + str(subalpha_run) +';' + \n",
    "                                   str(eta) +';' + str(gamma_run) + ';' + str(ch_score) + ';' + str(ll_score)  + '\\n')\n",
    "                    print('------------------------------')\n",
    "                    \n",
    "                else: break\n",
    "\n",
    "        elif model_name == 'HLDAModel':\n",
    "                \n",
    "            # Setting parameters dict for different eta values\n",
    "            level_run = level\n",
    "            gamma_run = gamma\n",
    "            subalpha_run = None\n",
    "            params = {'depth':level_run, 'alpha':myalpha, 'eta':eta, 'gamma':gamma_run, 'seed':seed}\n",
    "                \n",
    "            # Initialization of the model with parameters\n",
    "            model = eval('to.' + model_name)(**params)\n",
    "            # Download documents\n",
    "            list(map(model.add_doc, words_in_docs))\n",
    "    \n",
    "            # Train the model\n",
    "            model.train(workers=workers, iter=iter)\n",
    "            # Get evaluation metrics\n",
    "            ch_score = coherence.Coherence(model, top_n = 50).get_score()\n",
    "            ll_score = model.ll_per_word\n",
    "    \n",
    "            #Print iteration\n",
    "            print('Model: {} \\nNum of topics: {} \\nEta: {} \\nCoherence: {} \\nLog-likelihood: {}'.format(model_name, model.live_k, eta, \n",
    "                                                                                                            ch_score, ll_score))\n",
    "            #Recording the results to a csv file\n",
    "            with open(myfile, 'a') as file: \n",
    "                    file.write(model_name + ';' + str(level_run) + ';' + str(model.live_k) + ';' + str(myalpha) +';' + str(subalpha_run) +';' + \n",
    "                               str(eta) +';' + str(gamma_run) + ';' + str(ch_score) + ';' + str(ll_score)  + '\\n')\n",
    "            print('------------------------------')\n",
    "\n",
    "stop = time.time()\n",
    "print('\\nTime of execution (sec)', stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bc65e2-b297-4094-9ea6-8ed68bf24c2c",
   "metadata": {},
   "source": [
    "## Scores for fitted TM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "034c5754-ac1b-44a6-b784-d7e97dc7add0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Depth (levels)</th>\n",
       "      <th>Num of topics</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Subalpha</th>\n",
       "      <th>Eta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Log-likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDAModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.577870</td>\n",
       "      <td>-8.635659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDAModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.615020</td>\n",
       "      <td>-8.757591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDAModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.820211</td>\n",
       "      <td>-8.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDAModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.035691</td>\n",
       "      <td>-8.797220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDAModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.106559</td>\n",
       "      <td>-8.821438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>CTModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.835077</td>\n",
       "      <td>-8.131752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>CTModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.863277</td>\n",
       "      <td>-8.345074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>CTModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.125357</td>\n",
       "      <td>-8.430885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>CTModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.684633</td>\n",
       "      <td>-8.492314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>CTModel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.361967</td>\n",
       "      <td>-8.549276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Depth (levels)  Num of topics  Alpha  Subalpha      Eta  Gamma  \\\n",
       "0    LDAModel             NaN              5  0.001       NaN  0.00001    NaN   \n",
       "1    LDAModel             NaN             10  0.001       NaN  0.00001    NaN   \n",
       "2    LDAModel             NaN             15  0.001       NaN  0.00001    NaN   \n",
       "3    LDAModel             NaN             20  0.001       NaN  0.00001    NaN   \n",
       "4    LDAModel             NaN             25  0.001       NaN  0.00001    NaN   \n",
       "..        ...             ...            ...    ...       ...      ...    ...   \n",
       "205   CTModel             NaN             30  0.001       NaN  1.00000    NaN   \n",
       "206   CTModel             NaN             40  0.001       NaN  1.00000    NaN   \n",
       "207   CTModel             NaN             50  0.001       NaN  1.00000    NaN   \n",
       "208   CTModel             NaN             60  0.001       NaN  1.00000    NaN   \n",
       "209   CTModel             NaN             70  0.001       NaN  1.00000    NaN   \n",
       "\n",
       "     Coherence  Log-likelihood  \n",
       "0    -1.577870       -8.635659  \n",
       "1    -1.615020       -8.757591  \n",
       "2    -1.820211       -8.811911  \n",
       "3    -2.035691       -8.797220  \n",
       "4    -2.106559       -8.821438  \n",
       "..         ...             ...  \n",
       "205  -2.835077       -8.131752  \n",
       "206  -4.863277       -8.345074  \n",
       "207  -7.125357       -8.430885  \n",
       "208  -7.684633       -8.492314  \n",
       "209  -8.361967       -8.549276  \n",
       "\n",
       "[210 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.read_csv(myfile, sep=';')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218855c-2caa-4755-974e-07440fe5c70e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
